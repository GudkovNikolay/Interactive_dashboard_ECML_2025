import torch
import pandas as pd
import numpy as np

from library.constants import DEVICE, N_ASSETS, WINDOW_SIZE


@torch.no_grad()
def generate_samples(generator, assets: list[str], n_samples: int = 1) -> pd.DataFrame | list[pd.DataFrame]:
    """
    Generate random samples from generator
    If n_samples > 1, then generate samples with shifted noise
    """
    generator.eval()
    z = generator.get_shifted_noise(n_samples).to(DEVICE)
    samples = generator(z).cpu()
    # print(f'n_samples = {n_samples}, samples.shape = {samples.shape}')
    if n_samples == 1:
        # Return one sample
        samples = samples.squeeze()
        assert samples.size() == (N_ASSETS, WINDOW_SIZE)
        return pd.DataFrame(samples.T, columns=assets)
    else:
        # Return multiple samples
        # dfs = []
        # for sample in samples:
        #     assert sample.size() == (N_ASSETS, WINDOW_SIZE)
        #     dfs.append(pd.DataFrame(sample.T, columns=assets))
        return samples


def generate_fake_returns(generator, df_returns_real: pd.DataFrame, seed: int) -> pd.DataFrame:
    torch.random.manual_seed(seed)
    # Create list of consequent samples
    print(f'Gen amount = {len(df_returns_real) / WINDOW_SIZE}')
    dfs = generate_samples(generator, df_returns_real.columns, int(len(df_returns_real) / WINDOW_SIZE)+1)
    print('dfs.shape = ', np.array(dfs).shape)
    # Merge generated DataFrames
    df_returns_fake = _merge_generated_dfs(dfs, df_returns_real)
    print('shape after merg', df_returns_fake.shape)
    # Normalize fake returns
    # df_returns_fake = _normalize_returns(df_returns_fake, df_returns_real)
    return df_returns_fake


def _merge_generated_dfs(dfs: list[pd.DataFrame], df_returns_real: pd.DataFrame) -> pd.DataFrame:
    """
    Merge consequent dfs generated by TCN network
    """
    result = np.concatenate(np.array(dfs), axis=1)
    # for i, df in enumerate(dfs[1:]):
    #     print('df shape =', np.array(df).shape)
    #     prev_df = dfs[i]
    #     # assert np.allclose(prev_df.iloc[31:].values, df.iloc[30:-1].values), f'{(~np.isclose(prev_df.iloc[30:].values, df.iloc[29:-1].values)).sum(), }'
    #     result.append(df)
    dfs = pd.DataFrame(result[:, :df_returns_real.shape[0]].transpose())
    print(f'dfs = {dfs}')
    return dfs.set_index(df_returns_real.index)


def _normalize_returns(df_returns_fake: pd.DataFrame, df_returns_real: pd.DataFrame) -> pd.DataFrame:
    """
    Normalize generated samples to have the same mean and standard deviation as real returns
    """
    # Normalize to N(0, 1)
    df_returns_fake = df_returns_fake.sub(df_returns_fake.mean(), axis=1)
    df_returns_fake = df_returns_fake.div(df_returns_fake.std(), axis=1)
    # Normalize to N(mu, sigma)
    df_returns_fake = df_returns_fake.mul(df_returns_real.std(), axis=1)
    df_returns_fake = df_returns_fake.add(df_returns_real.mean(), axis=1)
    # Sanity check
    assert np.allclose(df_returns_fake.mean(), df_returns_real.mean()) and np.allclose(df_returns_fake.std(), df_returns_real.std())
    return df_returns_fake
