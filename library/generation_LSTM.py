import torch
import pandas as pd
import numpy as np

from constants import DEVICE, N_ASSETS, WINDOW_SIZE


@torch.no_grad()
def generate_samples(generator, assets: list[str], n_samples: int = 1) -> pd.DataFrame | list[pd.DataFrame]:
    """
    Generate random samples from generator
    If n_samples > 1, then generate samples with shifted noise
    """
    generator.eval()
    z = generator.get_shifted_noise(n_samples).to(DEVICE)
    samples = generator(z).cpu()
    print(n_samples, samples.shape)
    if n_samples == 1:
        # Return one sample
        samples = samples.squeeze().reshape(N_ASSETS, WINDOW_SIZE)
        assert samples.size() == (N_ASSETS, WINDOW_SIZE)
        return pd.DataFrame(samples.T, columns=assets)
    else:
        # Return multiple sample
        dfs = []
        samples = samples.reshape(n_samples, N_ASSETS, WINDOW_SIZE)
        for sample in samples:
            assert sample.size() == (N_ASSETS, WINDOW_SIZE)
            dfs.append(pd.DataFrame(sample.T, columns=assets))
        print(len(dfs))
        return dfs


def generate_fake_returns(generator, df_returns_real: pd.DataFrame, seed: int) -> pd.DataFrame:
    torch.random.manual_seed(seed)
    # Create list of consequent samples
    dfs = generate_samples(generator, df_returns_real.columns, len(df_returns_real) - WINDOW_SIZE + 1)
    # Merge generated DataFrames
    df_returns_fake = _merge_generated_dfs(dfs, df_returns_real)
    print('shape after merg', df_returns_fake.shape)
    # Normalize fake returns
    df_returns_fake = _normalize_returns(df_returns_fake, df_returns_real)
    return df_returns_fake


def _merge_generated_dfs(dfs: list[pd.DataFrame], df_returns_real: pd.DataFrame) -> pd.DataFrame:
    """
    Merge consequent dfs generated by TCN network
    """
    result = [dfs[0]]
    for i, df in enumerate(dfs[1:]):
        prev_df = dfs[i]
        # assert np.allclose(prev_df.iloc[31:].values, df.iloc[30:-1].values), f'{(~np.isclose(prev_df.iloc[30:].values, df.iloc[29:-1].values)).sum(), }'
        result.append(df.iloc[-1:])
    return pd.concat(result).set_index(df_returns_real.index)


def _normalize_returns(df_returns_fake: pd.DataFrame, df_returns_real: pd.DataFrame) -> pd.DataFrame:
    """
    Normalize generated samples to have the same mean and standard deviation as real returns
    """
    # Normalize to N(0, 1)
    df_returns_fake = df_returns_fake.sub(df_returns_fake.mean(), axis=1)
    df_returns_fake = df_returns_fake.div(df_returns_fake.std(), axis=1)
    # Normalize to N(mu, sigma)
    df_returns_fake = df_returns_fake.mul(df_returns_real.std(), axis=1)
    df_returns_fake = df_returns_fake.add(df_returns_real.mean(), axis=1)
    # Sanity check
    assert np.allclose(df_returns_fake.mean(), df_returns_real.mean()) and np.allclose(df_returns_fake.std(), df_returns_real.std())
    return df_returns_fake
