import torch
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from library.constants import DEVICE, N_ASSETS, WINDOW_SIZE

@torch.no_grad()
def generate_samples(generator, assets: list[str], n_samples: int = 1) -> pd.DataFrame | list[pd.DataFrame]:
    """
    Generate random samples from generator
    If n_samples > 1, then generate samples with shifted noise
    """
    generator.eval()
    z = generator.get_shifted_noise(n_samples).to(DEVICE)
    samples = generator(z).cpu()
    if n_samples == 1:
        # Return one sample
        samples = samples.squeeze()
        assert samples.size() == (N_ASSETS, WINDOW_SIZE)
        return pd.DataFrame(samples.T, columns=assets)
    else:
        # Return multiple samples
        dfs = []
        for sample in samples:
            assert sample.size() == (N_ASSETS, WINDOW_SIZE)
            dfs.append(pd.DataFrame(sample.T, columns=assets))
        return dfs


def generate_fake_returns(generator, df_returns_real: pd.DataFrame, seed: int) -> pd.DataFrame:
    torch.random.manual_seed(seed)
    # Create list of consequent samples
    dfs = generate_samples(generator, df_returns_real.columns, len(df_returns_real) - WINDOW_SIZE + 1)
    # Merge generated DataFrames
    df_returns_fake = _merge_generated_dfs(dfs, df_returns_real)
    # Normalize fake returns
    df_returns_fake = _normalize_returns(df_returns_fake, df_returns_real)
    return df_returns_fake


def _merge_generated_dfs(dfs: list[pd.DataFrame], df_returns_real: pd.DataFrame) -> pd.DataFrame:
    """
    Merge consequent dfs generated by TCN network
    """
    result = [dfs[0]]
    for i, df in enumerate(dfs[1:]):
        prev_df = dfs[i]
        # TODO этот ассерт важен?
        # try:
        #     assert np.allclose(prev_df.iloc[31:].values, df.iloc[30:-1].values, atol=1e-06)
        # except:
        #     plt.plot(np.array(prev_df.iloc[1:].values - df.iloc[:-1].values))
        #     plt.title(f'Broken generation, batch_num = {i}')
        #     plt.show()

        result.append(df.iloc[-1:])
    return pd.concat(result).set_index(df_returns_real.index)


def _normalize_returns(df_returns_fake: pd.DataFrame, df_returns_real: pd.DataFrame) -> pd.DataFrame:
    """
    Normalize generated samples to have the same mean and standard deviation as real returns
    """
    # Normalize to N(0, 1)
    df_returns_fake = df_returns_fake.sub(df_returns_fake.mean(), axis=1)
    df_returns_fake = df_returns_fake.div(df_returns_fake.std(), axis=1)
    # Normalize to N(mu, sigma)
    df_returns_fake = df_returns_fake.mul(df_returns_real.std(), axis=1)
    df_returns_fake = df_returns_fake.add(df_returns_real.mean(), axis=1)
    # Sanity check
    assert np.allclose(df_returns_fake.mean(), df_returns_real.mean()) and np.allclose(df_returns_fake.std(), df_returns_real.std())
    return df_returns_fake
